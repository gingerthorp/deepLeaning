{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL5_summary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcqgL9Px/xbHzZ69UTbAKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gingerthorp/deepLeaning/blob/master/study/5_Learn%20the%20training%20Know-how/DL5_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MQoVap3N6af",
        "colab_type": "text"
      },
      "source": [
        "# 5. 훈련 노하우를 배웁니다.\n",
        "\n",
        "목적 : 모든 신경망과 머신러닝 알고리즘을 다룰 때 필요한 훈련 노하우를 배웁니다.\n",
        "목표 : 전처리, 적합상태, 규제 방법, 교차 검증을 실습합니다.\n",
        "\n",
        "### 목차\n",
        "> 5.1 검증 세트를 나누고 전처리 과정을 배웁니다.  \n",
        "> 5.2 과대적합과 과소적합을 알아봅니다.  \n",
        "> 5.3 규제 방법을 배우고 단일층 신경망에 적용합니다.  \n",
        "> 5.4 교차 검증을 알아보고 사이킷런으로 수행해 봅니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x_Q1KKRRf4L",
        "colab_type": "text"
      },
      "source": [
        "#### 5.1 검증 세트를 나누고 전처리 과정을 배웁니다.\n",
        "4장에서 위스콘신 유방암 데이터 세트를 두 덩어리로 나눈 '훈련 세트'와 '테스트 세트'를 준비했습니다.  \n",
        "훈련 세트는 fit() 메서드에 전달되어 모델을 훈련하는데 사용하였고, 테스트 세트는 score() 메서드에 전달해 모델의 성능을 평가했죠.  \n",
        "*여기서는 '테스트 세트'의 사용 방법에 대해 조금 더 깊이 알아보려 합니다.*\n",
        "**목표는 '어느 데이터 세트에만 치우친 모델을 만들지 않는 것' 입니다.**\n",
        "\n",
        "> 테스트 세트로 모델을 튜닝합니다.\n",
        "\n",
        "SGDClassifier클래스에서 loss 매개변수 값을 log로 지정하여\n",
        "로지스틱 손실 함수를 손실 함수로 지정했습니다.\n",
        "\n",
        "1. 로지스틱 회귀로 모델 훈련하고 평가하기\n",
        "2. 서포트 벡터 머신으로 모델 훈련하고 평가하기\n",
        "\n",
        "**결론**  \n",
        "모델의 성능이 만족스럽지 않다면, loss매개변수에 다른 값을 적용하듯이 SGDClassifier 클래스의 다른 매개변수들을 바꿔보면 됩니다.\n",
        "\n",
        "이런 작업들을 '모델을 튜닝한다'고 합니다.\n",
        "\n",
        "'모델을 튜닝'하여 좋은 성능을 내는 모델을 만들어보았습니다.\n",
        "\n",
        "**그런데 이 모델은 실전에서 좋은 성능을 내지 못할 확률이 높습니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbgXdKKke9Te",
        "colab_type": "text"
      },
      "source": [
        "> 테스트 세트로 모델을 튜닝하면 실전에서 좋은 성능을 기대하기 어렵습니다.\n",
        "\n",
        "테스트 세트에 대해서만 좋은 성능을 낼 수 있도록 모델을 튜닝하면 실전에서 같은 성능을 기대하기 어렵습니다. 이런 현상을 '테스트 세트의 정보가 새어 나갔다'라고 말합니다.  \n",
        "정리하면 테스트 세트로 모델을 튜닝하면 테스트 세트의 정보가 모델에 새어 나가므로 모델의 일반화 성능(generlization performance)이 왜곡됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rbRAmTfAU_",
        "colab_type": "text"
      },
      "source": [
        "> 검증 세트를 준비합니다.\n",
        "\n",
        "왜곡되지 않기 위해서 모델을 튜닝할 때 테스트 세트를 사용하지 않으면 됩니다. 하지만 모델을 튜닝하려면 성능 점수가 필요합니다.\n",
        "따라서 테스트 세트는 모델을 실전 투입하기 전에 딱 한 번만 사용하는 것이 좋습니다. 즉, 모델 튜닝을 위한 세트는 따로 준비해야 합니다.\n",
        "\n",
        "모델을 튜닝하는 용도의 세트는 검증 세트(validation set)라고 하며 훈련 세트를 조금 떼어 만듭니다.\n",
        "\n",
        "\n",
        "**결론**\n",
        "1. 위스콘신 유방암 데이터 세트의 샘플 개수는 적음.\n",
        "2. 데이터 양이 적으면 매개변수의 값을 조금만 조절했을 때 성능평가 점수가 크게 바뀜.\n",
        "3. 데이터 양이 적은 경우에 검증 세트를 나누지 않고 교차 검증(cross validation)방법을 쓰기도함.\n",
        "4. 요즘은 대량의 훈련 데이터를 손쉽게 모을 수 있음.\n",
        "5. 일반적으로 10만 개 정도 데이터가 있다면 8:1:1 정도로 분할함.\n",
        "6. 딥러닝은 이보다 더 많은 데이터, 100만 개 사용하면 98:1:1 정도의 비율로 샘플을 나눔.\n",
        "7. 일반적으로 검증과 테스트 세트의 샘플 수를 1만 개 이상 확보할 수 있다면 훈련 세트에 많은 샘플을 할당하는 것이 좋음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmJWBMiQfCoh",
        "colab_type": "text"
      },
      "source": [
        "> 데이터 전처리와 특성의 스케일을 알아봅니다.\n",
        "\n",
        "사이킷런 머신러닝 패키지에 준비된 데이터는 실습을 위한 것이므로 잘 가공되어 있습니다. 하지만 실전에서 수집된 데이터는 그렇지 않습니다.  \n",
        "이런 경우 데이터를 적절히 가공하는 '데이터 전처리(data preprocessing)'과정이 필요합니다.\n",
        "\n",
        "**특성의 스케일은 알고리즘에 영향을 줍니다**\n",
        "스케일이란 어떤 특성을 가지고 있는 값의 범위를 말합니다.\n",
        "지금까지 소개되었던 신경망 알고리즘들은 경사 하강법을 사용했습니다.  \n",
        "경사 하강법은 스케일에 민감한 알고리즘이므로 특성의 스케일에 맞추는등의 전처리를 해야 합니다.  \n",
        "이때 특성의 스케일을 전처리하는 것을 '스케일을 조정한다'라고 표현합니다.\n",
        "\n",
        "**스케일을 조정해 모델을 훈련시킬떄 주의할 점.**  \n",
        "훈련 세트 스케일을 표준화하여 학습하였을 때 검증 세트와 테스트 세트 또한 스케일을 표준화해줘야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Fvz7fimFEd",
        "colab_type": "text"
      },
      "source": [
        "> 스케일을 조정한 다음에 실수하기 쉬운 함정을 알아봅니다.\n",
        "\n",
        "함정이란 '훈련 세트와 검증 세트가 다른 비율로 스케일이 조정된 경우'를 말합니다.\n",
        "\n",
        "훈련 세트, 검증 세트를 각각 다른 비율로 전처리를 주의해야 합니다.\n",
        "\n",
        "해결 방법 : 훈련 세트의 평균, 표준 편차를 사용하여 검증 세트를 변환하면 됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7MGTrmXnNOb",
        "colab_type": "text"
      },
      "source": [
        "#### 5.2 과대적합과 과소적합을 알아봅니다."
      ]
    }
  ]
}